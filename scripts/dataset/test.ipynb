{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pathlib\n",
    "import json\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "USEFUL_CHANNELS = [\n",
    "\"FP1-F7\",\n",
    "\"F7-T7\",\n",
    "\"T7-P7\",\n",
    "\"P7-O1\",\n",
    "\"FP1-F3\",\n",
    "\"F3-C3\",\n",
    "\"C3-P3\",\n",
    "\"P3-O1\",\n",
    "\"FP2-F4\",\n",
    "\"F4-C4\",\n",
    "\"C4-P4\",\n",
    "\"P4-O2\",\n",
    "\"FP2-F8\",\n",
    "\"F8-T8\",\n",
    "\"T8-P8\",\n",
    "\"P8-O2\",\n",
    "\"FZ-CZ\",\n",
    "\"CZ-PZ\",\n",
    "\"P7-T7\",\n",
    "\"T7-FT9\",\n",
    "\"FT9-FT10\",\n",
    "\"FT10-T8\",\n",
    "\"T8-P8\",\n",
    "]\n",
    "\n",
    "# new_names = dict(\n",
    "#     (ch_name,\n",
    "#     ch_name.rstrip('.').upper().replace('Z', 'z').replace('FP', 'Fp'))\n",
    "#     for ch_name in USEFUL_CHANNELS)\n",
    "# USEFUL_CHANNELS = [new_names[x] for x in USEFUL_CHANNELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "MISSING = ['O1-P7', 'O2-P4', 'F8-FP2', 'F7-T7', 'F4-FP2', 'CZ-PZ', 'O1-P3', 'CZ-FZ', 'F3-FP1', 'F8-T8', 'C3-P3', 'F7-FP1', 'O2-P8', 'P8-T8', 'C3-F3', 'C4-P4', 'C4-F4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting EDF parameters from /media/HDD/Unisa/Datasets/CHB_MIT/chb12/chb12_27.edf...\n",
      "EDF file detected\n",
      "Setting channel info structure...\n",
      "Creating raw.info structure...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5567/3143991756.py:3: RuntimeWarning: Channel names are not unique, found duplicates for: {'-'}. Applying running numbers for duplicates.\n",
      "  raw = mne.io.read_raw_edf(path)\n",
      "/tmp/ipykernel_5567/3143991756.py:3: RuntimeWarning: Scaling factor is not defined in following channels:\n",
      "--0, --1, --2, --3, --4\n",
      "  raw = mne.io.read_raw_edf(path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['F7-CS2',\n",
       " 'T7-CS2',\n",
       " 'P7-CS2',\n",
       " '--0',\n",
       " 'FP1-CS2',\n",
       " 'F3-CS2',\n",
       " 'C3-CS2',\n",
       " 'P3-CS2',\n",
       " 'O1-CS2',\n",
       " '--1',\n",
       " 'FZ-CS2',\n",
       " 'CZ-CS2',\n",
       " 'PZ-CS2',\n",
       " '--2',\n",
       " 'FP2-CS2',\n",
       " 'F4-CS2',\n",
       " 'C4-CS2',\n",
       " 'P4-CS2',\n",
       " 'O2-CS2',\n",
       " '--3',\n",
       " 'F8-CS2',\n",
       " 'T8-CS2',\n",
       " 'P8-CS2',\n",
       " '--4',\n",
       " 'C2-CS2',\n",
       " 'C6-CS2',\n",
       " 'CP2-CS2',\n",
       " 'CP4-CS2',\n",
       " 'CP6-CS2']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = pathlib.Path(\"/media/HDD/Unisa/Datasets/CHB_MIT/chb12/chb12_27.edf\")\n",
    "\n",
    "raw = mne.io.read_raw_edf(path)\n",
    "\n",
    "raw.ch_names\n",
    "# for ch in MISSING:\n",
    "#     for found_ch in raw.ch_names:\n",
    "#         if ch in found_ch:\n",
    "#             print(f\"{ch} ~ {found_ch}\")\n",
    "# data = raw.get_data()\n",
    "    \n",
    "# channel1 = data[raw.ch_names.index(\"T8-P8-0\"), :]\n",
    "# channel2 = data[raw.ch_names.index(\"T8-P8-1\"), :]\n",
    "\n",
    "\n",
    "# new_names = dict(\n",
    "#     (ch_name,\n",
    "    # #  ch_name.rstrip('.').upper().replace('Z', 'z').replace('FP', 'Fp'))\n",
    "#     # for ch_name in raw.ch_names)\n",
    "# # raw.rename_channels(new_names)\n",
    "\n",
    "# # new_names = dict(\n",
    "#     # (ch_name,\n",
    "    # #  ch_name.rstrip('.').upper().replace('Z', 'z').replace('FP', 'Fp'))\n",
    "#     # for ch_name in USEFUL_CHANNELS)\n",
    "# USEFUL_CHANNELS = [new_names[x] for x in USEFUL_CHANNELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"table table-hover table-striped table-sm table-responsive small\">\n",
       "    <tr>\n",
       "        <th>Measurement date</th>\n",
       "        \n",
       "        <td>February 17, 2057  18:23:13 GMT</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Experimenter</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "        <th>Participant</th>\n",
       "        \n",
       "        <td>Unknown</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Digitized points</th>\n",
       "        \n",
       "        <td>3 points</td>\n",
       "        \n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Good channels</th>\n",
       "        <td>31 EEG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>Bad channels</th>\n",
       "        <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>EOG channels</th>\n",
       "        <td>Not available</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <th>ECG channels</th>\n",
       "        <td>Not available</td>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Sampling frequency</th>\n",
       "        <td>256.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Highpass</th>\n",
       "        <td>0.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Lowpass</th>\n",
       "        <td>128.00 Hz</td>\n",
       "    </tr>\n",
       "    \n",
       "    \n",
       "    \n",
       "    <tr>\n",
       "        <th>Filenames</th>\n",
       "        <td>chb15_01.edf</td>\n",
       "    </tr>\n",
       "    \n",
       "    <tr>\n",
       "        <th>Duration</th>\n",
       "        <td>01:00:02 (HH:MM:SS)</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<RawEDF | chb15_01.edf, 31 x 922112 (3602.0 s), ~36 kB, data not loaded>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montage = mne.channels.make_standard_montage(\"standard_1020\")\n",
    "raw.set_montage(montage, on_missing=\"ignore\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw contains 31\n",
      "Missing\n",
      "P7-T7\n",
      "T7-FT9\n",
      "FT9-FT10\n",
      "FT10-T8\n",
      "\n",
      "Extra\n",
      "--0\n",
      "--1\n",
      "--2\n",
      "--3\n",
      "--4\n",
      "FC1-REF\n",
      "FC2-REF\n",
      "FC5-REF\n",
      "FC6-REF\n",
      "CP1-REF\n",
      "CP2-REF\n",
      "CP5-REF\n",
      "CP6-REF\n"
     ]
    }
   ],
   "source": [
    "print(\"raw contains\", len(raw.ch_names))\n",
    "\n",
    "print(\"Missing\")\n",
    "for channel in USEFUL_CHANNELS:\n",
    "    if channel not in raw.ch_names:\n",
    "        print(channel)\n",
    "\n",
    "print(\"\\nExtra\")\n",
    "for channel in raw.ch_names:\n",
    "    if channel not in USEFUL_CHANNELS:\n",
    "        print(channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "montage = mne.channels.make_standard_montage(\"standard_1005\")\n",
    "\n",
    "# exclude = [\"(?i).*-REF\", \".*-Ref\", \"ECG\", \"VNS\"]\n",
    "# for channel in COMMON_CHANNELS.split(\",\"):\n",
    "#     for i in range(5):\n",
    "#         exclude.append(f\"{channel}-{i+1}\")\n",
    "\n",
    "def read_data(path):\n",
    "    raw = mne.io.read_raw_edf(path, stim_channel=None, include=COMMON_CHANNELS, verbose=\"ERROR\")\n",
    "\n",
    "    if \"T8-P8-1\" in raw.ch_names:\n",
    "        raw.drop_channels(\"T8-P8-1\")\n",
    "        new_names = {\"T8-P8-0\": \"T8-P8\"}\n",
    "        raw.rename_channels(new_names)\n",
    "\n",
    "    raw.reorder_channels(COMMON_CHANNELS)\n",
    "\n",
    "\n",
    "    # new_names = dict(\n",
    "    #     (ch_name,\n",
    "    #     ch_name.rstrip('.').upper().replace('Z', 'z').replace('FP', 'Fp'))\n",
    "    #     for ch_name in raw.ch_names)\n",
    "    # raw.rename_channels(new_names)\n",
    "\n",
    "    # raw = raw.set_montage(montage, on_missing=\"ignore\")\n",
    "\n",
    "    # new_ch_names = raw.ch_names\n",
    "    return raw.ch_names\n",
    "\n",
    "    # if len(new_ch_names) < len(original_ch_names):\n",
    "    #     raise f\"Canali diminuiti in {path}\"\n",
    "\n",
    "    # return raw\n",
    "    # parsed_ch_names = sorted(set([\"-\".join(channel.split(\"-\")[:2]) for channel in original_ch_names if not channel.startswith(\"--\")]))\n",
    "    # return \",\".join(parsed_ch_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "COMMON_CHANNELS = [\n",
    "    \"FP1-F7\",\n",
    "    \"F7-T7\",\n",
    "    \"T7-P7\",\n",
    "    \"P7-O1\",\n",
    "    \"FP1-F3\",\n",
    "    \"F3-C3\",\n",
    "    \"C3-P3\",\n",
    "    \"P3-O1\",\n",
    "    \"FP2-F4\",\n",
    "    \"F4-C4\",\n",
    "    \"C4-P4\",\n",
    "    \"P4-O2\",\n",
    "    \"FP2-F8\",\n",
    "    \"F8-T8\",\n",
    "    \"P8-O2\",\n",
    "    \"FZ-CZ\",\n",
    "    \"CZ-PZ\",\n",
    "    \"T8-P8\"\n",
    "]\n",
    "# COMMON_CHANNELS = [\"-\".join(sorted(channel.split(\"-\")[:2])) for channel in COMMON_CHANNELS]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'.-3', 'C6', 'CP2', 'P7-O1', 'T8-P8-1', 'F4', 'FP2', 'C4-CS2', 'O2', 'F7-T7', 'P7', 'C6-CS2', 'CP2-CS2', 'FZ', 'F3-C3', 'PZ', 'CP6-CS2', '.-0', 'O1-CS2', 'C4-P4', 'P8', 'P3-CS2', '.-4', '.-1', 'C4', 'CP4-CS2', 'FP2-CS2', 'T7', 'EKG1-CHIN', 'P8-O2', 'F4-CS2', 'F7', 'FT10-T8', 'C2', 'CP6', 'P3', 'FZ-CS2', '01', 'F7-CS2', 'F8', 'CZ-CS2', 'F8-T8', 'FP1-F3', 'T8-CS2', 'CP4', 'C3', 'T8', 'C3-P3', 'LUE-RAE', 'FP1', 'FT9-FT10', 'P7-T7', 'CZ-PZ', 'O2-CS2', 'P7-CS2', 'T7-P7', 'EKG1-EKG2', 'T7-CS2', 'FZ-CZ', 'C3-CS2', 'F8-CS2', 'T7-FT9', 'FP1-F7', 'F4-C4', 'PZ-CS2', 'CZ', 'P3-O1', 'FP2-F8', '.-2', 'P4-CS2', 'T8-P8-0', 'F3', 'T8-P8', 'F3-CS2', 'PZ-OZ', 'P4-O2', 'LOC-ROC', 'FP2-F4', 'C2-CS2', 'FP1-CS2', 'P4', 'P8-CS2'}\n",
      "len(every_channel)=82\n",
      "missing_channels={'O1-P7', 'O2-P4', 'F8-FP2', 'F4-FP2', 'O1-P3', 'CZ-FZ', 'F3-FP1', 'F7-FP1', 'O2-P8', 'P8-T8', 'C3-F3', 'C4-F4'}\n"
     ]
    }
   ],
   "source": [
    "slices_path = pathlib.Path(\"output/300/slices.json\")\n",
    "dataset_path = pathlib.Path(\"/media/HDD/Unisa/Datasets/CHB_MIT\")\n",
    "with open(slices_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "dirs = (path for path in dataset_path.iterdir() if path.is_dir())\n",
    "\n",
    "# for directory in dirs:\n",
    "#     for edfpath in (edfpath for edfpath in directory.iterdir() if edfpath.name.endswith(\"edf\")):\n",
    "#         minimum = read_data(edfpath)\n",
    "#         channels.add(minimum)\n",
    "\n",
    "count = 563\n",
    "\n",
    "# filter_out_regex = [\"(?i).*-REF\", \"ECG\", \"VNS\", \".*--.*\"]\n",
    "filter_out_regex = [\"(?i).*-REF\", \".*--.*\", \"ECG\", \"VNS\"]\n",
    "\n",
    "every_channel = set()\n",
    "for patient, files_data in data.items():\n",
    "    for filename, slices in files_data.items():\n",
    "        edf_path = dataset_path.joinpath(patient, filename)\n",
    "        # raw = read_data(path)\n",
    "        channels = read_data(edf_path)\n",
    "        for channel in channels:\n",
    "            if not any(re.match(regex, channel) for regex in filter_out_regex):\n",
    "                every_channel.add(channel)\n",
    "\n",
    "print(every_channel)\n",
    "print(f\"{len(every_channel)=}\")\n",
    "\n",
    "missing_channels = set()\n",
    "for channel in COMMON_CHANNELS:\n",
    "    if channel not in every_channel:\n",
    "        missing_channels.add(channel)\n",
    "\n",
    "print(f\"{missing_channels=}\")\n",
    "\n",
    "for channel in missing_channels:\n",
    "    for found_channel in every_channel:\n",
    "        if channel in found_channel:\n",
    "            print(f\"{channel} in {found_channel}\")\n",
    "        # if minimum != COMMON_CHANNELS:\n",
    "        #     print(f\"{edf_path} {minimum}\")\n",
    "        # channels.add(minimum)\n",
    "\n",
    "# print(channels)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing_channels={'O1-P7', 'O2-P4', 'F8-FP2', 'F7-T7', 'F4-FP2', 'CZ-PZ', 'O1-P3', 'CZ-FZ', 'F3-FP1', 'F8-T8', 'C3-P3', 'F7-FP1', 'O2-P8', 'P8-T8', 'P7-T7', 'C3-F3', 'C4-P4', 'C4-F4'} edf_path=PosixPath('/media/HDD/Unisa/Datasets/CHB_MIT/chb12/chb12_27.edf')\n",
      "missing_channels={'O1-P7', 'O2-P4', 'F8-FP2', 'F7-T7', 'F4-FP2', 'CZ-PZ', 'O1-P3', 'CZ-FZ', 'F3-FP1', 'F8-T8', 'C3-P3', 'F7-FP1', 'O2-P8', 'P8-T8', 'P7-T7', 'C3-F3', 'C4-P4', 'C4-F4'} edf_path=PosixPath('/media/HDD/Unisa/Datasets/CHB_MIT/chb12/chb12_28.edf')\n",
      "missing_channels={'O1-P7', 'O2-P4', 'F8-FP2', 'F7-T7', 'F4-FP2', 'CZ-PZ', 'O1-P3', 'CZ-FZ', 'F3-FP1', 'F8-T8', 'C3-P3', 'F7-FP1', 'O2-P8', 'P8-T8', 'P7-T7', 'C3-F3', 'C4-P4', 'C4-F4'} edf_path=PosixPath('/media/HDD/Unisa/Datasets/CHB_MIT/chb12/chb12_29.edf')\n"
     ]
    }
   ],
   "source": [
    "slices_path = pathlib.Path(\"output/300/slices.json\")\n",
    "dataset_path = pathlib.Path(\"/media/HDD/Unisa/Datasets/CHB_MIT\")\n",
    "with open(slices_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "dirs = (path for path in dataset_path.iterdir() if path.is_dir())\n",
    "\n",
    "# for directory in dirs:\n",
    "#     for edfpath in (edfpath for edfpath in directory.iterdir() if edfpath.name.endswith(\"edf\")):\n",
    "#         minimum = read_data(edfpath)\n",
    "#         channels.add(minimum)\n",
    "\n",
    "count = 563\n",
    "\n",
    "# filter_out_regex = [\"(?i).*-REF\", \"ECG\", \"VNS\", \".*--.*\"]\n",
    "filter_out_regex = [\"(?i).*-REF\", \".*--.*\", \"ECG\", \"VNS\"]\n",
    "\n",
    "every_channel = set()\n",
    "for patient, files_data in data.items():\n",
    "    for filename, slices in files_data.items():\n",
    "        edf_path = dataset_path.joinpath(patient, filename)\n",
    "        # raw = read_data(path)\n",
    "        channels = read_data(edf_path)\n",
    "        actual_channels = set()\n",
    "        for channel in channels:\n",
    "            channel = \"-\".join(sorted(channel.split(\"-\")[:2]))\n",
    "            if not any(re.match(regex, channel) for regex in filter_out_regex):\n",
    "                actual_channels.add(channel)\n",
    "        missing_channels = set()\n",
    "        for channel in COMMON_CHANNELS:\n",
    "            if channel not in actual_channels:\n",
    "                missing_channels.add(channel)\n",
    "        \n",
    "        if len(missing_channels):\n",
    "            print(f\"{missing_channels=} {edf_path=}\")\n",
    "\n",
    "            for channel in missing_channels:\n",
    "                for found_channel in actual_channels:\n",
    "                    if channel in found_channel:\n",
    "                        print(f\"{channel} in {found_channel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISCARDED_EDFS = [\n",
    "    \"chb12_27.edf\",\n",
    "    \"chb12_28.edf\",\n",
    "    \"chb12_29.edf\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_path = pathlib.Path(\"output/300/slices.json\")\n",
    "dataset_path = pathlib.Path(\"/media/HDD/Unisa/Datasets/CHB_MIT\")\n",
    "with open(slices_path) as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "dirs = (path for path in dataset_path.iterdir() if path.is_dir())\n",
    "\n",
    "channel_configurations = set()\n",
    "channel_amounts = set()\n",
    "for patient, files_data in data.items():\n",
    "    for filename, slices in files_data.items():\n",
    "        edf_path = dataset_path.joinpath(patient, filename)\n",
    "        if edf_path.name not in DISCARDED_EDFS:\n",
    "            # raw = read_data(path)\n",
    "            channels = read_data(edf_path)\n",
    "            channel_configurations.add(tuple(channels))\n",
    "            if len(channels) == 20:\n",
    "                pass\n",
    "            else:\n",
    "                channel_amounts.add(len(channels))\n",
    "\n",
    "for conf in channel_configurations:\n",
    "    for ch in COMMON_CHANNELS:\n",
    "        if ch not in conf:\n",
    "            print(conf, ch)\n",
    "\n",
    "# print(channel_amounts)\n",
    "print(f\"{channel_configurations=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['standard_1005',\n",
       " 'standard_1020',\n",
       " 'standard_alphabetic',\n",
       " 'standard_postfixed',\n",
       " 'standard_prefixed',\n",
       " 'standard_primed',\n",
       " 'biosemi16',\n",
       " 'biosemi32',\n",
       " 'biosemi64',\n",
       " 'biosemi128',\n",
       " 'biosemi160',\n",
       " 'biosemi256',\n",
       " 'easycap-M1',\n",
       " 'easycap-M10',\n",
       " 'EGI_256',\n",
       " 'GSN-HydroCel-32',\n",
       " 'GSN-HydroCel-64_1.0',\n",
       " 'GSN-HydroCel-65_1.0',\n",
       " 'GSN-HydroCel-128',\n",
       " 'GSN-HydroCel-129',\n",
       " 'GSN-HydroCel-256',\n",
       " 'GSN-HydroCel-257',\n",
       " 'mgh60',\n",
       " 'mgh70',\n",
       " 'artinis-octamon',\n",
       " 'artinis-brite23',\n",
       " 'brainproducts-RNP-BA-128']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mne.channels.get_builtin_montages()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('thesis')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b5368fd8657fddaac09694b2d32a0dd8498de270d43315e8a8f62f877f9cb72d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
